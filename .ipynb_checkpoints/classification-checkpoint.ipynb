{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 967704 entries, 0 to 967703\n",
      "Data columns (total 4 columns):\n",
      "Resource        967704 non-null object\n",
      "comment         967704 non-null object\n",
      "Publish Date    967704 non-null object\n",
      "label           40628 non-null float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 29.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_comments = pd.read_csv('./labels/df_comments1033.csv', encoding='utf-8', header=0, sep='|', engine='python')\n",
    "df_comments.drop(['URL', 'comment_lower', 'label_type', 'label(auto)', 'sa_prediction'], axis=1, inplace=True)\n",
    "df_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>comment</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682183</th>\n",
       "      <td>youtube_russia24tv</td>\n",
       "      <td>Россия вперед!﻿</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275051</th>\n",
       "      <td>fb_ria</td>\n",
       "      <td>Экономим на старье, а следовательно на человеч...</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139057</th>\n",
       "      <td>fb_lentaru</td>\n",
       "      <td>Так Коля шпилил Мотю, или нет? Запутали. Пойду...</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622924</th>\n",
       "      <td>youtube_russia24tv</td>\n",
       "      <td>Кисель Мудак проплаченный Путиным.﻿</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559335</th>\n",
       "      <td>youtube_russia24tv</td>\n",
       "      <td>а с вашими как?﻿</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Resource                                            comment  \\\n",
       "682183  youtube_russia24tv                                    Россия вперед!﻿   \n",
       "275051              fb_ria  Экономим на старье, а следовательно на человеч...   \n",
       "139057          fb_lentaru  Так Коля шпилил Мотю, или нет? Запутали. Пойду...   \n",
       "622924  youtube_russia24tv                Кисель Мудак проплаченный Путиным.﻿   \n",
       "559335  youtube_russia24tv                                   а с вашими как?﻿   \n",
       "\n",
       "       Publish Date  label  \n",
       "682183   2018-02-17    NaN  \n",
       "275051   2018-02-11    NaN  \n",
       "139057   2017-09-21    NaN  \n",
       "622924   2018-02-04    NaN  \n",
       "559335   2018-01-16    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32502,)\n",
      "(8126,)\n",
      "(32502,)\n",
      "(8126,)\n",
      "(556246,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "abuse_comments = df_comments.loc[df_comments.label == 1]['comment']\n",
    "common_comments = df_comments.loc[df_comments.label == 0]['comment']\n",
    "unsup_comments = df_comments.loc[df_comments.label.isnull()]['comment']\n",
    "\n",
    "unsup_comments = unsup_comments.sample(frac=0.6) # иначе memory error при обучении doc2vec\n",
    "\n",
    "#use 1 for abuse comments, 0 for common comments\n",
    "y = np.concatenate((np.ones(len(abuse_comments)), np.zeros(len(common_comments))))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.concatenate((abuse_comments, common_comments)), y, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(unsup_comments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготавливаю тексты для Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "def cleanText(corpus, lemmatize=True, dropStopwords=True, dropPunctuation=True):\n",
    "    \n",
    "    stem = Mystem()\n",
    "    http_match = 'http[s]?://(?:[a-zA-Zа-яА-Я]|[0-9]|[$-_@.&#+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    email_match = '[a-z.-]+@[a-z.-]{4,}'\n",
    "    \n",
    "    corpus = [z.lower().replace('\\n',' ') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "    corpus = [z.replace('ё', 'е') for z in corpus]\n",
    "    corpus = [z.replace('\\ufeff', '') for z in corpus]\n",
    "    corpus = [re.sub(http_match, 'link', z) for z in corpus] #заменяю ссылки на 'Link'\n",
    "    corpus = [re.sub(email_match, 'email', z) for z in corpus] #заменяю e-mail на 'email'\n",
    "    \n",
    "    if dropPunctuation:\n",
    "        corpus = [re.sub(\"[^а-яА-Яa-zA-Z0-9]\",\" \", z) for z in corpus] #заменяю пунктуацию на пробелы\n",
    "    else:\n",
    "        punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "        for c in punctuation:\n",
    "            corpus = [z.replace(c, ' %s '%c) for z in corpus] #выделяю пунктуацию в отдельные слова\n",
    "                  \n",
    "    corpus = [z.split() for z in corpus]\n",
    "    \n",
    "    if dropStopwords: #удаляю английские и русские стопслова\n",
    "        russian_stopwords = stopwords.words(\"russian\")\n",
    "        stopwords_extension = ['ко']\n",
    "        russian_stopwords = russian_stopwords + stopwords_extension\n",
    "        stopwords_exclusion = ['не', 'нет', 'нельзя']\n",
    "        for word in stopwords_exclusion:\n",
    "            russian_stopwords.remove(word)\n",
    "        stops = set(stopwords.words(\"english\")) | set(russian_stopwords)\n",
    "        for i, z in enumerate(corpus):\n",
    "            corpus[i] = [w for w in corpus[i] if not w in stops]  \n",
    "    \n",
    "    if lemmatize: #лемматизация\n",
    "        for i, z in enumerate(corpus):\n",
    "            for j, w in enumerate(z):\n",
    "                corpus[i][j] = stem.lemmatize(w)[0]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 56s, sys: 1min 50s, total: 6min 46s\n",
      "Wall time: 12min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)\n",
    "unsup_comments = cleanText(unsup_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "#We do this by using the LabeledSentence method. The format will be \"ALL_i\" where \"i\" is\n",
    "#a dummy index of the comment\n",
    "import gensim\n",
    "TaggedDocument = gensim.models.doc2vec.TaggedDocument\n",
    "\n",
    "def labelizeComments(comments, label_type):\n",
    "    labelized = []\n",
    "    for i, v in enumerate(comments):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(TaggedDocument(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x = labelizeComments(np.concatenate((x_train, x_test, unsup_comments)), 'ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['danil', 'leontyev', 'насчет', 'чечня', 'не', 'доказывать', 'хрюндель', 'трусливый', 'польша', 'пиздеть', 'сартира', 'мыть', 'нанимать', 'кричать', 'шыпча', 'курва', 'шипкий'], tags=['ALL_0']),\n",
       " TaggedDocument(words=['лопарь', 'коми', 'ижемец', 'продолжать', 'жить', 'мурманский', 'область', 'здоровье', 'все', 'мурманск', 'наверное', 'первый', 'мир', 'место', 'памятник', 'занимать'], tags=['ALL_1']),\n",
       " TaggedDocument(words=['путин', 'хуйло', 'скоро', 'мутко', 'везде', 'забанить'], tags=['ALL_2']),\n",
       " TaggedDocument(words=['путин', 'вор'], tags=['ALL_3']),\n",
       " TaggedDocument(words=['интересно', 'икона', 'фото', 'путлер', 'начинать', 'проверка'], tags=['ALL_4']),\n",
       " TaggedDocument(words=['тупой', 'чучело', 'соснуть', 'хуйца', 'затыкаться'], tags=['ALL_5']),\n",
       " TaggedDocument(words=['грузия', 'скорбеть', 'вместе', 'мир', 'слишком', 'жестокий', 'забирать', 'самый', 'нужный', 'молодой', 'продолжать', 'жить', 'чтить', 'память', 'уходить', 'вечный', 'память'], tags=['ALL_6']),\n",
       " TaggedDocument(words=['жаль', 'здоровье', 'не', 'позволять', 'продолжать', 'актерский', 'деятельность', 'замечательный', 'талантливый', 'актриса', 'давать', 'бог', 'здоровье', 'долгий', 'год'], tags=['ALL_7']),\n",
       " TaggedDocument(words=['поздравлять', 'девчонка'], tags=['ALL_8']),\n",
       " TaggedDocument(words=['идти', 'нах', 'сдыхать', 'чучело', 'ольгинский'], tags=['ALL_9'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SIZE = 400\n",
    "WORKERS = 4\n",
    "EPOCHS = 55\n",
    "\n",
    "#instantiate our DM and DBOW models\n",
    "model_dm = gensim.models.doc2vec.Doc2Vec(min_count=1, window=10, vector_size=SIZE, sample=1e-3, negative=5, workers=WORKERS, epochs=EPOCHS)\n",
    "model_dbow = gensim.models.doc2vec.Doc2Vec(min_count=1, window=10, vector_size=SIZE, sample=1e-3, negative=5, dm=0, workers=WORKERS, epochs=EPOCHS)\n",
    "\n",
    "#build vocab over all comments\n",
    "model_dm.build_vocab(x)\n",
    "model_dbow.build_vocab(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model_dm...\n",
      "training model_dbow...\n",
      "(596874, 800)\n",
      "CPU times: user 2h 42min 23s, sys: 19min 35s, total: 3h 1min 59s\n",
      "Wall time: 1h 23min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('training model_dm...')\n",
    "model_dm.train(x, total_examples=model_dm.corpus_count, epochs=model_dm.epochs)\n",
    "\n",
    "print('training model_dbow...')\n",
    "model_dbow.train(x, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
    "\n",
    "#Get vectors from our models\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [np.array(model[z.tags[0]]).reshape((1, SIZE)) for z in corpus]\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "vecs_dm = getVecs(model_dm, x, SIZE)\n",
    "vecs_dbow = getVecs(model_dbow, x, SIZE)\n",
    "\n",
    "vecs = np.hstack((vecs_dm, vecs_dbow))\n",
    "print(vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_vecs = vecs[:len(x_train)]\n",
    "x_test_vecs = vecs[len(x_train):(len(x_train) + len(x_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 32502, x_train_vecs: (32502, 800)\n",
      "x_test: 8126, x_test_vecs: (8126, 800)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: {}, x_train_vecs: {}'.format(len(x_train), x_train_vecs.shape))\n",
    "print('x_test: {}, x_test_vecs: {}'.format(len(x_test), x_test_vecs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаю модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 490.94, NNZs: 670, Bias: 10.661405, T: 32502, Avg. loss: 5.925750\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 467.93, NNZs: 660, Bias: 10.128212, T: 65004, Avg. loss: 2.116436\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 456.31, NNZs: 651, Bias: 10.087766, T: 97506, Avg. loss: 1.621785\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 448.84, NNZs: 647, Bias: 9.767422, T: 130008, Avg. loss: 1.378446\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 443.44, NNZs: 643, Bias: 10.034874, T: 162510, Avg. loss: 1.239176\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 439.29, NNZs: 640, Bias: 9.247927, T: 195012, Avg. loss: 1.136799\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 435.94, NNZs: 640, Bias: 9.428653, T: 227514, Avg. loss: 1.060800\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 433.17, NNZs: 635, Bias: 9.517491, T: 260016, Avg. loss: 0.996448\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 430.82, NNZs: 634, Bias: 9.267237, T: 292518, Avg. loss: 0.946004\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 428.81, NNZs: 636, Bias: 8.869410, T: 325020, Avg. loss: 0.906233\n",
      "Total training time: 3.27 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 427.03, NNZs: 635, Bias: 9.087247, T: 357522, Avg. loss: 0.867704\n",
      "Total training time: 3.61 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 425.47, NNZs: 632, Bias: 8.743541, T: 390024, Avg. loss: 0.836288\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 424.05, NNZs: 629, Bias: 8.912818, T: 422526, Avg. loss: 0.809751\n",
      "Total training time: 4.29 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 422.79, NNZs: 628, Bias: 8.863389, T: 455028, Avg. loss: 0.783924\n",
      "Total training time: 4.63 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 421.64, NNZs: 627, Bias: 8.800575, T: 487530, Avg. loss: 0.761607\n",
      "Total training time: 4.97 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 420.59, NNZs: 625, Bias: 8.640242, T: 520032, Avg. loss: 0.740730\n",
      "Total training time: 5.31 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 419.62, NNZs: 624, Bias: 8.407707, T: 552534, Avg. loss: 0.722253\n",
      "Total training time: 5.66 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 418.73, NNZs: 625, Bias: 8.429519, T: 585036, Avg. loss: 0.705835\n",
      "Total training time: 6.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 417.90, NNZs: 623, Bias: 8.233168, T: 617538, Avg. loss: 0.690273\n",
      "Total training time: 6.35 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 417.13, NNZs: 619, Bias: 8.386640, T: 650040, Avg. loss: 0.673365\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 416.41, NNZs: 618, Bias: 8.250832, T: 682542, Avg. loss: 0.661613\n",
      "Total training time: 7.05 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 415.74, NNZs: 618, Bias: 8.103459, T: 715044, Avg. loss: 0.648177\n",
      "Total training time: 7.38 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 415.11, NNZs: 614, Bias: 7.891438, T: 747546, Avg. loss: 0.636592\n",
      "Total training time: 7.72 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 414.50, NNZs: 616, Bias: 8.059695, T: 780048, Avg. loss: 0.624975\n",
      "Total training time: 8.06 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 413.94, NNZs: 613, Bias: 7.988084, T: 812550, Avg. loss: 0.614548\n",
      "Total training time: 8.40 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 413.41, NNZs: 611, Bias: 7.794437, T: 845052, Avg. loss: 0.604684\n",
      "Total training time: 8.75 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 412.90, NNZs: 611, Bias: 7.826846, T: 877554, Avg. loss: 0.595502\n",
      "Total training time: 9.10 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 412.42, NNZs: 611, Bias: 7.728507, T: 910056, Avg. loss: 0.586879\n",
      "Total training time: 9.44 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 411.96, NNZs: 610, Bias: 7.578022, T: 942558, Avg. loss: 0.578027\n",
      "Total training time: 9.79 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 411.53, NNZs: 609, Bias: 7.523970, T: 975060, Avg. loss: 0.569864\n",
      "Total training time: 10.14 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 411.11, NNZs: 609, Bias: 7.553953, T: 1007562, Avg. loss: 0.562898\n",
      "Total training time: 10.49 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 410.71, NNZs: 606, Bias: 7.478516, T: 1040064, Avg. loss: 0.555263\n",
      "Total training time: 10.83 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 410.33, NNZs: 603, Bias: 7.445156, T: 1072566, Avg. loss: 0.548384\n",
      "Total training time: 11.18 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 409.96, NNZs: 603, Bias: 7.505144, T: 1105068, Avg. loss: 0.541608\n",
      "Total training time: 11.55 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 409.61, NNZs: 600, Bias: 7.463334, T: 1137570, Avg. loss: 0.535313\n",
      "Total training time: 11.90 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 409.27, NNZs: 600, Bias: 7.297159, T: 1170072, Avg. loss: 0.528615\n",
      "Total training time: 12.26 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 408.94, NNZs: 601, Bias: 7.274004, T: 1202574, Avg. loss: 0.523228\n",
      "Total training time: 12.60 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 408.63, NNZs: 600, Bias: 7.302117, T: 1235076, Avg. loss: 0.518346\n",
      "Total training time: 12.94 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 408.33, NNZs: 600, Bias: 7.252276, T: 1267578, Avg. loss: 0.512811\n",
      "Total training time: 13.27 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 408.03, NNZs: 599, Bias: 7.197708, T: 1300080, Avg. loss: 0.506983\n",
      "Total training time: 13.61 seconds.\n",
      "Test Accuracy: 0.9312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgdc = SGDClassifier(loss='log', penalty='l1', max_iter=40, verbose=1, n_jobs=-1)\n",
    "sgdc.fit(x_train_vecs, y_train)\n",
    "\n",
    "print('Test Accuracy: %.4f'%sgdc.score(x_test_vecs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9094\n",
      "Recall: 0.9203\n",
      "F1-measure: 0.9149\n",
      "Accuracy: 0.9312\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0     0.9461    0.9385    0.9423      4863\n",
      "        1.0     0.9094    0.9203    0.9149      3263\n",
      "\n",
      "avg / total     0.9314    0.9312    0.9313      8126\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEICAYAAACpqsStAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMpW7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74e46e33c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "predictions = sgdc.predict(x_test_vecs)\n",
    "print(\"Precision: {0:6.4f}\".format(precision_score(y_test, predictions)))\n",
    "print(\"Recall: {0:6.4f}\".format(recall_score(y_test, predictions)))\n",
    "print(\"F1-measure: {0:6.4f}\".format(f1_score(y_test, predictions)))\n",
    "print(\"Accuracy: {0:6.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions, digits=4))\n",
    "labels = sgdc.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimasta SD, ахаха идиоты, мировое сообщество признаёт украинскую конституцию         (где строго написано что судьбы регионов решаются референдумом во всех 25 регионах         а не в одном), поэтому ваши воровские хитрожопые хотелки можете себе в задницу         засунуть, придётся отдавать крым украине как вор отдаёт отжатую мобилу владельцу         под присмотром ментов без всяких там хуерендумов. Правильно делает владиофшорович         что разваливает под санкциями рашку и делат вату нищей, вы дауны на лучшее не         заслуживаете, сучары лицемерные хD\n",
      "\n",
      "оскорбительный\n"
     ]
    }
   ],
   "source": [
    "def abusement_check(text):\n",
    "    text_ = cleanText([text])\n",
    "    vec = np.hstack((model_dm.infer_vector(text_[0], steps=150), model_dbow.infer_vector(text_[0], steps=150)))\n",
    "    prediction = sgdc.predict([vec])\n",
    "    print(text)\n",
    "    if prediction == 1:\n",
    "        print('\\nоскорбительный')\n",
    "    else:\n",
    "        print('\\nнеоскорбительный')\n",
    "\n",
    "text = 'Dimasta SD, ахаха идиоты, мировое сообщество признаёт украинскую конституцию \\\n",
    "        (где строго написано что судьбы регионов решаются референдумом во всех 25 регионах \\\n",
    "        а не в одном), поэтому ваши воровские хитрожопые хотелки можете себе в задницу \\\n",
    "        засунуть, придётся отдавать крым украине как вор отдаёт отжатую мобилу владельцу \\\n",
    "        под присмотром ментов без всяких там хуерендумов. Правильно делает владиофшорович \\\n",
    "        что разваливает под санкциями рашку и делат вату нищей, вы дауны на лучшее не \\\n",
    "        заслуживаете, сучары лицемерные хD'\n",
    "abusement_check(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
